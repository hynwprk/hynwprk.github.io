---
layout: post
title: "Humanity's Last Exam"
date: 2025-01-24 02:16:00 -0500
description: I was one of the top contributors for Humanity's Last Exam. 14 of my submissions were accepted.
tags: [machine-learning, benchmarks]
categories: [research]
related_posts: false
thumbnail: assets/img/publication_preview/hle.jpeg
---

I was one of the top contributors for [Humanity's Last Exam](https://lastexam.ai)!

A total of 14 of my submissions were accepted: 12 public and 2 private. Many problems are from computational game theory, and some problems are in algebra and general relativity.

One or more of my submitted questions was selected as part of the top 550 for HLE, which won me a total prize of $500 from Scale AI for being a top 550 contributor.

Thanks to [Richard Stanley](https://math.mit.edu/~rstan/) my Erdos number is now 3.

## What is HLE?

Humanity's Last Exam is a multi-modal benchmark at the frontier of human knowledge, designed to be the final closed-ended academic benchmark with broad subject coverage. It consists of 3,000 questions across dozens of subjects, including mathematics, humanities, and the natural sciences. The benchmark was developed globally by subject-matter experts and published in [Nature](https://doi.org/10.1038/s41586-025-09962-4).

State-of-the-art LLMs demonstrate low accuracy and calibration on HLE, highlighting a significant gap between current LLM capabilities and the expert human frontier on closed-ended academic questions.

## Links

- Paper: [arXiv:2501.14249](https://arxiv.org/abs/2501.14249)
- Nature: [10.1038/s41586-025-09962-4](https://doi.org/10.1038/s41586-025-09962-4)
- Website: [lastexam.ai](https://lastexam.ai)
